{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Unit 3 Homework: parse/convert string regex to API\n",
      "\n",
      "REGRAMMMER = grammar(\"\"\"\n",
      "RE => ## your description here\n",
      "\"\"\", whitespace='')\n",
      "\n",
      "def parse_re(pattern) :\n",
      "    return convert(parse('RE', pattern, REGRAMMER))\n",
      "\n",
      "def convert(tree) :\n",
      "    # your code here\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-1-18d69ac12b78>, line 12)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-18d69ac12b78>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#grammar.py\n",
      "\n",
      "import functools\n",
      "import re\n",
      "\n",
      "def grammar(description, whitespace = r'\\s*'):\n",
      "    \"\"\"\n",
      "    Convert a description to a grammar. Each line is a rule for a\n",
      "    non-terminal symbol; it looks like this:\n",
      "\n",
      "        Symbol => A1 A2 ... | B1 B2 ... | C1 C2 ...\n",
      "\n",
      "    where the right-hand side is one or more alternatives, separated by\n",
      "    the '|' sign. Each alternative is a sequence of atoms, separated by\n",
      "    spaces.  An atom is either a symbol on syme left-hand side, or it is a\n",
      "    regular expression that will be passed to re.match to match a token.\n",
      "\n",
      "    Notation for *, +, or ? not allowed in a rule alternative (but ok within a\n",
      "    token). Use '\\' to continue long lines. You must include spaces or tabs\n",
      "    around '=>' and '|'. That's within the grammar description itself(...?). The\n",
      "    grammar that gets defined allows whitespace between tokens by default or\n",
      "    specify '' as the second argument to grammar() to disallow this (or supply\n",
      "    any regular expression to describe allowable whitespace between\n",
      "    tokens).\"\"\"\n",
      "    G = {' ': whitespace}\n",
      "    description = description.replace('\\t', ' ') # no tabs!\n",
      "    for line in split(description, '\\n'):\n",
      "        lhs, rhs = split(line, ' => ', 1)\n",
      "        alternatives = split(rhs, ' | ')\n",
      "        G[lhs] = tuple(map(split, alternatives))\n",
      "    return G\n",
      "\n",
      "def split(text, sep = None, maxsplit = -1):\n",
      "    \"Like str.split applied to text, but strips whitespace from each piece.\"\n",
      "    return [t.strip() for t in text.strip().split(sep, maxsplit) if t]\n",
      "\n",
      "def parse(start_symbol, text, grammar):\n",
      "    \"\"\"Example call: parse('Exp', '3*x + b', G).\n",
      "    Returns a (tree, remainder) pair. If remainder is '', it parsed the whole\n",
      "    string. Failure iff remainder is None. This is a deterministic PEG parser,\n",
      "    so rule order (left-to-right) matters. Do 'E => T op E | T', putting the\n",
      "    longest parse first; don't do 'E => T | T op E'\n",
      "    Also, no left recursion allowed: don't do 'E => E op T'\n",
      "\n",
      "    See: http://en.wikipedia.org/wiki/Parsing_expression_grammar\n",
      "    \"\"\"\n",
      "\n",
      "    tokenizer = grammar[' '] + '(%s)'\n",
      "\n",
      "    def parse_sequence(sequence, text):\n",
      "        \"\"\"\n",
      "        Try to match the sequence of atoms against text.\n",
      "\n",
      "        Parameters:\n",
      "        sequence : an iterable of atoms\n",
      "        text : a string\n",
      "\n",
      "        Returns:\n",
      "        Fail : if any atom in sequence does not match\n",
      "        (tree, remainder) : the tree and remainder if the entire sequence matches text\n",
      "        \"\"\"\n",
      "        result = []\n",
      "        for atom in sequence:\n",
      "            tree, text = parse_atom(atom, text)\n",
      "            if text is None: return Fail\n",
      "            result.append(tree)\n",
      "        return result, text\n",
      "\n",
      "    @memo\n",
      "    def parse_atom(atom, text):\n",
      "        \"\"\"\n",
      "        Parameters:\n",
      "        atom : either a key in grammar or a regular expression\n",
      "        text : a string\n",
      "\n",
      "        Returns:\n",
      "        Fail : if no match can be found\n",
      "        (tree, remainder) : if a match is found\n",
      "            tree is the parse tree of the first match found\n",
      "            remainder is the text that was not matched\n",
      "        \"\"\"\n",
      "        if atom in grammar:  # Non-Terminal: tuple of alternatives\n",
      "            for alternative in grammar[atom]:\n",
      "                tree, rem = parse_sequence(alternative, text)\n",
      "                if rem is not None: return [atom]+tree, rem\n",
      "            return Fail\n",
      "        else:  # Terminal: match characters against start of text\n",
      "            m = re.match(tokenizer % atom, text)\n",
      "            return Fail if (not m) else (m.group(1), text[m.end():])\n",
      "\n",
      "    return parse_atom(start_symbol, text)\n",
      "\n",
      "Fail = (None, None)\n",
      "\n",
      "def decorator(d):\n",
      "    \"Make function d a decorator: d wraps a function fn.\"\n",
      "    def _d(fn):\n",
      "        return functools.update_wrapper(d(fn), fn)\n",
      "    functools.update_wrapper(_d, d)\n",
      "    return _d\n",
      "\n",
      "@decorator\n",
      "def memo(f):\n",
      "    \"\"\"Decorator that caches the return value for each call to f(args).\n",
      "    Then when called again with same args, we can just look it up.\"\"\"\n",
      "    cache = {}\n",
      "    def _f(*args):\n",
      "        try:\n",
      "            return cache[args]\n",
      "        except KeyError:\n",
      "            cache[args] = result = f(*args)\n",
      "            return result\n",
      "        except TypeError:\n",
      "            # some element of args can't be a dict key\n",
      "            return f(*args)\n",
      "    _f.cache = cache\n",
      "    return _f\n",
      "\n",
      "G = grammar(r\"\"\"\n",
      "Exp => Term [+-] Exp | Term\n",
      "Term => Factor [*/] Term | Factor\n",
      "Factor => Funcall | Var | Num | [(] Exp [)]\n",
      "Funcall => Var [(] Exps [)]\n",
      "Exps => Exp [,] Exps | Exp\n",
      "Var => [a-zA-Z_]\\w*\n",
      "Num => [-+]?[0-9]+([.][0-9]*)?\n",
      "\"\"\")\n",
      "\n",
      "## Parsing URLs\n",
      "## See http://www.w3.org/Addressing/URL/5_BNF.html\n",
      "\n",
      "URL = grammar(\"\"\"\n",
      "url => httpaddress | ftpaddress | mailtoaddress\n",
      "httpaddress => http:// hostport /path? ?search?\n",
      "ftpaddress => ftp:// login / path ; ftptype | ftp:// login / path\n",
      "/path? => / path | ()\n",
      "?search? => [?] search | ()\n",
      "mailtoaddress => mailto: xalphas @ hostname\n",
      "hostport => host : port | host\n",
      "host => hostname | hostnumber\n",
      "hostname => ialpha . hostname | ialpha\n",
      "hostnumber => digits . digits . digits . digits\n",
      "ftptype => A formcode | E formcode | I | L digits\n",
      "formcode => [NTC]\n",
      "port => digits | path\n",
      "path => void | segment / path | segment\n",
      "segment => xalphas\n",
      "search => xalphas + search | xalphas\n",
      "login => userpassword hostport | hostport\n",
      "userpassword => user : password @ | user @\n",
      "user => alphanum2 user | alphanum2\n",
      "password => alphanum2 password | password\n",
      "path => void | segment / path | segment\n",
      "void => ()\n",
      "digits => digit digits | digit\n",
      "digit => [0-9]\n",
      "alpha => [a-zA-Z]\n",
      "safe => [-$_@.&+]\n",
      "extra => [()!*''\"\"]\n",
      "escape => % hex hex\n",
      "hex => [0-9a-fA-F]\n",
      "alphanum => alpha | digit\n",
      "alphanums => alphanum alphanums | alphanum\n",
      "alphanum2 => alpha | digit | [-_.+]\n",
      "ialpha => alpha xalphas | alpha\n",
      "xalphas => xalpha xalphas | xalpha\n",
      "xalpha => alpha | digit | safe | extra | escape\n",
      "\"\"\", whitespace = '()')\n",
      "\n",
      "def verify(G):\n",
      "    lhstokens = set(G) - set([' '])\n",
      "    print(G.values())\n",
      "    rhstokens = set(t for alts in G.values() for alt in alts for t in alt)\n",
      "    def show(title, tokens): print title, '=', ' '.join(map(repr, sorted(tokens)))\n",
      "    show('Non-Terms', G)\n",
      "    show('Terminals', rhstokens - lhstokens)\n",
      "    show('Suspects', [t for t in (rhstokens-lhstokens) if t.isalnum()])\n",
      "    show('Orphans ', lhstokens-rhstokens)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    # print(G)\n",
      "    verify(G)\n",
      "    print(parse('Exp', '3*x + b', G))\n",
      "\n",
      "    # print(URL)\n",
      "    # verify(URL)\n",
      "    # print(parse('url', 'http://www.w3.org/Addressing/URL/5_BNF.html', URL))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#regex interpreter.py\n",
      "def search(pattern, text):\n",
      "    \"Match pattern anywhere in text; return longest earliest match or None.\"\n",
      "    for i in range(len(text) or 1):\n",
      "        m = match(pattern, text[i:])\n",
      "        if m is not None: return m\n",
      "\n",
      "def match(pattern, text):\n",
      "    \"Match pattern against start of text; return longest match found or None.\"\n",
      "    remainders = matchset(pattern, text)\n",
      "    if remainders:\n",
      "        shortest = min(remainders, key = len)\n",
      "        return text[:len(text)-len(shortest)]\n",
      "\n",
      "def matchset(pattern, text):\n",
      "    \"Match pattern at start of text; return a set of remainders of text.\"\n",
      "    op, x, y = components(pattern)\n",
      "    if 'lit' == op:\n",
      "        return set([text[len(x):]]) if text.startswith(x) else null\n",
      "    elif 'seq' == op:\n",
      "        return set(t2 for t1 in matchset(x, text) for t2 in matchset(y, t1))\n",
      "    elif 'alt' == op:\n",
      "        return matchset(x, text) | matchset(y, text)\n",
      "    elif 'dot' == op:\n",
      "        return set([text[1:]]) if text else null\n",
      "    elif 'oneof' == op:\n",
      "        return set([text[1:]]) if text.startswith(tuple(x)) else null\n",
      "    elif 'eol' == op:\n",
      "        return set(['']) if text == '' else null\n",
      "    elif 'star' == op:\n",
      "        return (set([text]) |\n",
      "                set(t2 for t1 in matchset(x, text)\n",
      "                    for t2 in matchset(pattern, t1) if t1 != text))\n",
      "    else:\n",
      "        raise ValueError('unknown pattern: %s' % pattern)\n",
      "\n",
      "null = frozenset()\n",
      "\n",
      "def components(pattern):\n",
      "    \"Return the op, x, and y arguments; x and y are None if missing.\"\n",
      "    x = pattern[1] if len(pattern) > 1 else None\n",
      "    y = pattern[2] if len(pattern) > 2 else None\n",
      "    return pattern[0], x, y\n",
      "\n",
      "def lit(string):  return ('lit', string)\n",
      "def seq(x, y):    return ('seq', x, y)\n",
      "def alt(x, y):    return ('alt', x, y)\n",
      "def star(x):      return ('star', x)\n",
      "def plus(x):      return ('seq', x, ('star', x))\n",
      "def opt(x):       return alt(lit(''), x) #opt(x) means that x is optional\n",
      "def oneof(chars): return ('oneof', tuple(chars))\n",
      "dot = ('dot', )\n",
      "eol = ('eol', )\n",
      "\n",
      "def test():\n",
      "    assert match(('star', ('lit', 'a')), 'aaabcd') == 'aaa'\n",
      "    assert match(('alt', ('lit', 'b'), ('lit', 'c')), 'ab') == None\n",
      "    assert match(('alt', ('lit', 'b'), ('lit', 'a')), 'ab') == 'a'\n",
      "    assert search(('lit', ''), '') == ''\n",
      "    assert search(('alt', ('lit', 'b'), ('lit', 'c')), 'ab') == 'b'\n",
      "    assert matchset(('lit', 'abc'), 'abcdef')              == set(['def'])\n",
      "    assert matchset(('seq', ('lit', 'hi '),\n",
      "                     ('lit', 'there ')),\n",
      "                   'hi there nice to meet you')            == set(['nice to meet you'])\n",
      "    assert matchset(('alt', ('lit', 'dog'),\n",
      "                    ('lit', 'cat')), 'dog and cat')        == set([' and cat'])\n",
      "    assert (matchset(('dot', ), 'am i missing something?')\n",
      "            == set(['m i missing something?']))\n",
      "    assert matchset(('dot', ), '')                         == frozenset([])\n",
      "    assert matchset(('oneof', 'a'), 'aabc123')             == set(['abc123'])\n",
      "    assert matchset(('oneof', 'abc'), 'babc123')           == set(['abc123'])\n",
      "    assert matchset(('oneof', 'abc'), 'dabc123')           == frozenset([])\n",
      "    assert matchset(('eol', ), '')                         == set([''])\n",
      "    assert matchset(('eol', ), 'not end of line')          == frozenset([])\n",
      "    assert matchset(('star', ('lit', 'hey')), 'heyhey!') == set(['!', 'heyhey!', 'hey!'])\n",
      "\n",
      "    assert lit('abc')         == ('lit', 'abc')\n",
      "    assert seq(('lit', 'a'),\n",
      "               ('lit', 'b'))  == ('seq', ('lit', 'a'), ('lit', 'b'))\n",
      "    assert alt(('lit', 'a'),\n",
      "               ('lit', 'b'))  == ('alt', ('lit', 'a'), ('lit', 'b'))\n",
      "    assert star(('lit', 'a')) == ('star', ('lit', 'a'))\n",
      "    assert plus(('lit', 'c')) == ('seq', ('lit', 'c'),\n",
      "                                  ('star', ('lit', 'c')))\n",
      "    assert opt(('lit', 'x'))  == ('alt', ('lit', ''), ('lit', 'x'))\n",
      "    assert oneof('abc')       == ('oneof', ('a', 'b', 'c'))\n",
      "    return 'tests pass'\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    print test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# regex compiler.py\n",
      "\n",
      "def match(pattern, text):\n",
      "    \"Match pattern against start of text; return longest match found or None.\"\n",
      "    remainders = pattern(text)\n",
      "    if remainders:\n",
      "        shortest = min(remainders, key = len)\n",
      "        return text[:len(text)-len(shortest)]\n",
      "\n",
      "def search(pattern, text):\n",
      "    \"Match pattern anywhere in text; return longest earliest match or None.\"\n",
      "    for i in range(len(text) or 1):\n",
      "        m = match(pattern, text[i:])\n",
      "        if m is not None: return m\n",
      "\n",
      "def lit(s): return lambda t: set([t[len(s):]]) if t.startswith(s) else null\n",
      "def seq(x, y): return lambda t: set().union(*map(y, x(t)))\n",
      "def alt(x, y): return lambda t: x(t) | y(t)\n",
      "def oneof(chars): return lambda t: set([t[1:]]) if (t and t[0] in chars) else null\n",
      "def opt(x): return lambda t: alt(lit(''), x)(t)\n",
      "\n",
      "dot = lambda t: set([t[1:]]) if t else null\n",
      "eol = lambda t: set(['']) if t == '' else null\n",
      "def star(x): return lambda t: (set([t]) |\n",
      "                               set(t2 for t1 in x(t) if t1 != t\n",
      "                                   for t2 in star(x)(t1)))\n",
      "def plus(x): return lambda t: seq(x, star(x))(t)\n",
      "\n",
      "null = frozenset([])\n",
      "\n",
      "def test():\n",
      "    g = alt(lit('a'), lit('b'))\n",
      "    assert g('abc') == set(['bc'])\n",
      "\n",
      "    assert match(star(lit('a')), 'aaaaabbbaa') == 'aaaaa'\n",
      "    assert match(lit('hello'), 'hello how are you?') == 'hello'\n",
      "    assert match(lit('x'), 'hello how are you?') == None\n",
      "    assert match(oneof('xyz'), 'x**2 + y**2 = r**2') == 'x'\n",
      "    assert match(oneof('xyz'), '   x is here!') == None\n",
      "\n",
      "    assert match(star(lit('a')), 'aaabcd') == 'aaa'\n",
      "    assert match(lit('abc'), 'abc') == 'abc'\n",
      "    assert match(alt(lit('b'), lit('c')), 'ab') == None\n",
      "    assert match(alt(lit('b'), lit('a')), 'ab') == 'a'\n",
      "    assert search(lit(''), '') == ''\n",
      "    assert search(alt(lit('b'), lit('c')), 'ab') == 'b'\n",
      "    assert search(star(alt(lit('a'), lit('b'))), 'ab') == 'ab'\n",
      "    assert search(alt(lit('b'), lit('c')), 'ad') == None\n",
      "    assert lit('abc')('abcdef') == set(['def'])\n",
      "    assert (seq(lit('hi '), lit('there '))('hi there nice to meet you')\n",
      "            == set(['nice to meet you']))\n",
      "    assert alt(lit('dog'), lit('cat'))('dog and cat') == set([' and cat'])\n",
      "    assert dot('am i missing something?') == set(['m i missing something?'])\n",
      "    assert dot('') == frozenset([])\n",
      "    assert oneof('a')('aabc123') == set(['abc123'])\n",
      "    assert oneof('abc')('babc123') == set(['abc123'])\n",
      "    assert oneof('abc')('dabc123') == frozenset([])\n",
      "    assert eol('') == set([''])\n",
      "    assert eol('not end of line') == frozenset([])\n",
      "    assert star(lit('hey'))('heyhey!') == set(['!', 'heyhey!', 'hey!'])\n",
      "    assert plus(lit('hey'))('heyhey!') == set(['!', 'hey!'])\n",
      "    assert opt(lit('hey'))('heyhey!') == set(['hey!', 'heyhey!'])\n",
      "\n",
      "    return 'tests pass'\n",
      "\n",
      "print test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#regex generator.py\n",
      "\n",
      "def lit(s):         return lambda Ns: set([s]) if len(s) in Ns else null\n",
      "def alt(x, y):      return lambda Ns: x(Ns) | y(Ns)\n",
      "def star(x):        return lambda Ns: opt(plus(x))(Ns)\n",
      "def plus(x):        return lambda Ns: genseq(x, star(x), Ns, startx = 1) #Tricky\n",
      "def oneof(chars):   return lambda Ns: set(chars) if 1 in Ns else null\n",
      "def seq(x, y):      return lambda Ns: genseq(x, y, Ns)\n",
      "def opt(x):         return alt(epsilon, x)\n",
      "dot = oneof('?')    # You could expand the alphabet to more chars.\n",
      "epsilon = lit('')   # The pattern that matches the empty string.\n",
      "\n",
      "null = frozenset([])\n",
      "\n",
      "def genseq(x, y, Ns, startx = 0):\n",
      "    \"\"\"Set of matches to xy whose total len is in Ns, with x-match's len in Ns and\n",
      "    >= startx\"\"\"\n",
      "    # Tricky part: x+ is defined as: x+ = x x* To stop the recursion, the first x\n",
      "    # must generate at least 1 char, and then the recursive x* has that many fewer\n",
      "    # characters. We use startx = 1 to say that x must match at least 1 character\n",
      "    if not Ns:\n",
      "        return null\n",
      "    xmatches = x(set(range(startx, max(Ns)+1)))\n",
      "    Ns_x = set(len(m) for m in xmatches)\n",
      "    Ns_y = set(n-m for n in Ns for m in Ns_x if n-m >= 0)\n",
      "    ymatches = y(Ns_y)\n",
      "    return set(m1+m2 for m1 in xmatches for m2 in ymatches if len(m1+m2) in Ns)\n",
      "\n",
      "def test():\n",
      "    f = lit('hello')\n",
      "    assert f(set([1, 2, 3, 4, 5])) == set(['hello'])\n",
      "    assert f(set([1, 2, 3, 4]))    == null\n",
      "\n",
      "    g = alt(lit('hi'), lit('bye'))\n",
      "    assert g(set([1, 2, 3, 4, 5, 6])) == set(['bye', 'hi'])\n",
      "    assert g(set([1, 3, 5])) == set(['bye'])\n",
      "\n",
      "    h = oneof('theseletters')\n",
      "    assert h(set([1, 2, 3])) == set(['t', 'h', 'e', 's', 'l', 'r'])\n",
      "    assert h(set([2, 3, 4])) == null\n",
      "    return 'tests pass'\n",
      "\n",
      "def test_gen():\n",
      "    def N(hi):\n",
      "        return set(range(hi+1))\n",
      "    a, b, c = map(lit, 'abc')\n",
      "    assert star(oneof('ab'))(N(2)) == set(['', 'a', 'aa', 'ab', 'ba', 'bb', 'b'])\n",
      "    assert (seq(star(a), seq(star(b), star(c)))(set([4])) ==\n",
      "            set(['aaaa', 'aaab', 'aaac', 'aabb', 'aabc', 'aacc', 'abbb',\n",
      "                 'abbc', 'abcc', 'accc', 'bbbb', 'bbbc', 'bbcc', 'bccc', 'cccc']))\n",
      "    assert (seq(plus(a), seq(plus(b), plus(c)))(set([5])) ==\n",
      "            set(['aaabc', 'aabbc', 'aabcc', 'abbbc', 'abbcc', 'abccc']))\n",
      "    assert (seq(oneof('bcfhrsm'), lit('at'))(N(3)) ==\n",
      "            set(['bat', 'cat', 'fat', 'hat', 'mat', 'rat', 'sat']))\n",
      "    assert (seq(star(alt(a, b)), opt(c))(set([3])) ==\n",
      "            set(['aaa', 'aab', 'aac', 'aba', 'abb', 'abc', 'baa',\n",
      "                 'bab', 'bac', 'bba', 'bbb', 'bbc']))\n",
      "    assert lit('hello')(set([5])) == set(['hello'])\n",
      "    assert lit('hello')(set([4])) == set()\n",
      "    assert lit('hello')(set([6])) == set()\n",
      "    return 'test_gen passes'\n",
      "\n",
      "print(test())\n",
      "print(test_gen())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}